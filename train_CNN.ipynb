{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec68bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data2img import load_data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d3dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_dir, target_dir=None, size=32, regression=True):\n",
    "        if target_dir != None:\n",
    "            self.data, self.label = load_data(\n",
    "                input_dir, target_dir, size=size, regression=regression\n",
    "            )\n",
    "        else:\n",
    "            self.data = load_data(\n",
    "                input_dir, size=size, regression=regression\n",
    "            )\n",
    "            self.label = None\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        X = torch.from_numpy(self.data[idx]).float()\n",
    "        if self.label != None:\n",
    "            y = torch.from_numpy(np.array([self.label[idx]]))\n",
    "            return X, y.float()\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8b7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, size = 32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        if size ==32:\n",
    "            self.fc1 = nn.Linear(512, 256)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(4608, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f75b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "train_dataset = CausalDataset(\n",
    "    'data/train_pairs.csv', \n",
    "    'data/train_target.csv', \n",
    "    size = size, regression = False,\n",
    ")\n",
    "\n",
    "test_dataset = CausalDataset(\n",
    "    'data/valid_pairs.csv', \n",
    "    'data/valid_target.csv', \n",
    "    size = size, regression = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ba5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)\n",
    "testloader = DataLoader(test_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7eff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(size=size)\n",
    "# net = models.resnet18(pretrained = False)\n",
    "# net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# net.fc = nn.Linear(512, 1)\n",
    "###############################\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "###############################\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5683d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 9.293 train_acc: 0.746, train_auc: 0.500 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 2, loss: 9.145 train_acc: 0.747, train_auc: 0.500 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 3, loss: 9.051 train_acc: 0.747, train_auc: 0.500 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 4, loss: 8.876 train_acc: 0.747, train_auc: 0.500 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 5, loss: 8.744 train_acc: 0.748, train_auc: 0.507 test_acc: 0.768, test_auc: 0.498\n",
      "Epoch: 6, loss: 8.645 train_acc: 0.746, train_auc: 0.503 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 7, loss: 8.506 train_acc: 0.748, train_auc: 0.515 test_acc: 0.774, test_auc: 0.500\n",
      "Epoch: 8, loss: 8.416 train_acc: 0.755, train_auc: 0.529 test_acc: 0.782, test_auc: 0.537\n",
      "Epoch: 9, loss: 8.128 train_acc: 0.765, train_auc: 0.566 test_acc: 0.789, test_auc: 0.556\n",
      "Epoch: 10, loss: 7.880 train_acc: 0.772, train_auc: 0.582 test_acc: 0.775, test_auc: 0.555\n",
      "Epoch: 11, loss: 7.569 train_acc: 0.782, train_auc: 0.601 test_acc: 0.768, test_auc: 0.527\n",
      "Epoch: 12, loss: 7.193 train_acc: 0.800, train_auc: 0.637 test_acc: 0.791, test_auc: 0.573\n",
      "Epoch: 13, loss: 6.740 train_acc: 0.813, train_auc: 0.665 test_acc: 0.773, test_auc: 0.592\n",
      "Epoch: 14, loss: 6.338 train_acc: 0.825, train_auc: 0.689 test_acc: 0.775, test_auc: 0.543\n",
      "Epoch: 15, loss: 5.835 train_acc: 0.845, train_auc: 0.722 test_acc: 0.764, test_auc: 0.575\n",
      "Epoch: 16, loss: 5.384 train_acc: 0.856, train_auc: 0.741 test_acc: 0.767, test_auc: 0.586\n",
      "Epoch: 17, loss: 5.035 train_acc: 0.866, train_auc: 0.763 test_acc: 0.771, test_auc: 0.555\n",
      "Epoch: 18, loss: 4.556 train_acc: 0.879, train_auc: 0.783 test_acc: 0.769, test_auc: 0.591\n",
      "Epoch: 19, loss: 4.356 train_acc: 0.888, train_auc: 0.798 test_acc: 0.778, test_auc: 0.589\n",
      "Epoch: 20, loss: 4.220 train_acc: 0.893, train_auc: 0.808 test_acc: 0.761, test_auc: 0.593\n",
      "Epoch: 21, loss: 3.912 train_acc: 0.899, train_auc: 0.818 test_acc: 0.763, test_auc: 0.589\n",
      "Epoch: 22, loss: 3.542 train_acc: 0.907, train_auc: 0.832 test_acc: 0.774, test_auc: 0.604\n",
      "Epoch: 23, loss: 3.161 train_acc: 0.918, train_auc: 0.849 test_acc: 0.757, test_auc: 0.572\n",
      "Epoch: 24, loss: 3.200 train_acc: 0.915, train_auc: 0.846 test_acc: 0.758, test_auc: 0.588\n",
      "Epoch: 25, loss: 3.289 train_acc: 0.917, train_auc: 0.848 test_acc: 0.773, test_auc: 0.594\n",
      "Epoch: 26, loss: 2.800 train_acc: 0.925, train_auc: 0.862 test_acc: 0.777, test_auc: 0.606\n",
      "Epoch: 27, loss: 3.055 train_acc: 0.923, train_auc: 0.862 test_acc: 0.773, test_auc: 0.594\n",
      "Epoch: 28, loss: 2.653 train_acc: 0.931, train_auc: 0.873 test_acc: 0.769, test_auc: 0.601\n",
      "Epoch: 29, loss: 2.478 train_acc: 0.934, train_auc: 0.878 test_acc: 0.783, test_auc: 0.606\n",
      "Epoch: 30, loss: 2.500 train_acc: 0.933, train_auc: 0.879 test_acc: 0.773, test_auc: 0.601\n",
      "Epoch: 31, loss: 2.281 train_acc: 0.935, train_auc: 0.883 test_acc: 0.753, test_auc: 0.573\n",
      "Epoch: 32, loss: 2.700 train_acc: 0.932, train_auc: 0.881 test_acc: 0.729, test_auc: 0.615\n",
      "Epoch: 33, loss: 2.129 train_acc: 0.940, train_auc: 0.894 test_acc: 0.764, test_auc: 0.621\n",
      "Epoch: 34, loss: 2.231 train_acc: 0.941, train_auc: 0.896 test_acc: 0.768, test_auc: 0.602\n",
      "Epoch: 35, loss: 2.120 train_acc: 0.942, train_auc: 0.896 test_acc: 0.750, test_auc: 0.613\n",
      "Epoch: 36, loss: 2.337 train_acc: 0.940, train_auc: 0.896 test_acc: 0.769, test_auc: 0.582\n",
      "Epoch: 37, loss: 2.015 train_acc: 0.946, train_auc: 0.905 test_acc: 0.757, test_auc: 0.595\n",
      "Epoch: 38, loss: 1.879 train_acc: 0.947, train_auc: 0.910 test_acc: 0.773, test_auc: 0.603\n",
      "Epoch: 39, loss: 2.006 train_acc: 0.947, train_auc: 0.910 test_acc: 0.780, test_auc: 0.612\n",
      "Epoch: 40, loss: 1.747 train_acc: 0.954, train_auc: 0.920 test_acc: 0.739, test_auc: 0.604\n",
      "Epoch: 41, loss: 1.691 train_acc: 0.955, train_auc: 0.923 test_acc: 0.762, test_auc: 0.615\n",
      "Epoch: 42, loss: 1.713 train_acc: 0.952, train_auc: 0.919 test_acc: 0.744, test_auc: 0.601\n",
      "Epoch: 43, loss: 2.230 train_acc: 0.945, train_auc: 0.910 test_acc: 0.751, test_auc: 0.608\n",
      "Epoch: 44, loss: 1.595 train_acc: 0.959, train_auc: 0.931 test_acc: 0.763, test_auc: 0.606\n",
      "Epoch: 45, loss: 1.655 train_acc: 0.956, train_auc: 0.927 test_acc: 0.739, test_auc: 0.604\n",
      "Epoch: 46, loss: 1.528 train_acc: 0.959, train_auc: 0.932 test_acc: 0.741, test_auc: 0.590\n",
      "Epoch: 47, loss: 1.487 train_acc: 0.960, train_auc: 0.934 test_acc: 0.753, test_auc: 0.589\n",
      "Epoch: 48, loss: 1.759 train_acc: 0.956, train_auc: 0.926 test_acc: 0.755, test_auc: 0.580\n",
      "Epoch: 49, loss: 1.315 train_acc: 0.964, train_auc: 0.938 test_acc: 0.747, test_auc: 0.598\n",
      "Epoch: 50, loss: 1.443 train_acc: 0.963, train_auc: 0.937 test_acc: 0.747, test_auc: 0.592\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    'train_acc': [], 'train_auc':[],\n",
    "    'test_acc': [], 'test_auc': [],\n",
    "    'best_target': [], 'best_sub':[]\n",
    "}\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0\n",
    "    running_loss = 0.0\n",
    "    y = []\n",
    "    yhat = []\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y.append(labels.detach().numpy().flatten())\n",
    "        yhat.append(torch.round(torch.sigmoid(outputs.detach())).numpy().flatten())\n",
    "        # print statistics\n",
    "        epoch_loss += outputs.shape[0] * loss.item()\n",
    "    epoch_loss = epoch_loss/len(trainloader)\n",
    "    y, yhat = np.hstack(y), np.hstack(yhat)\n",
    "    correct = np.sum(y==yhat)\n",
    "    acc = correct/len(y)\n",
    "    auc = roc_auc_score(y, yhat)\n",
    "    \n",
    "    net.eval()\n",
    "    submission = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(inputs)\n",
    "            target.append(labels.detach().numpy().flatten())\n",
    "            submission.append(torch.round(torch.sigmoid(outputs.detach())).numpy().flatten())\n",
    "    submission = np.hstack(submission)\n",
    "    target = np.hstack(target)\n",
    "    test_correct = np.sum(target==submission)\n",
    "    test_acc = test_correct/len(target)\n",
    "    test_auc = roc_auc_score(target, submission)\n",
    "    \n",
    "    print(\n",
    "        f'Epoch: {epoch + 1}, loss: {epoch_loss:.3f} '+\n",
    "        f'train_acc: {acc:.3f}, train_auc: {auc:.3f} '+\n",
    "        f'test_acc: {test_acc:.3f}, test_auc: {test_auc:.3f}'\n",
    "    )\n",
    "    metrics['train_acc'].append(acc)\n",
    "    metrics['train_auc'].append(auc)\n",
    "    if len(metrics['test_auc']) > 0:\n",
    "        if test_auc > np.max(metrics['test_auc']):\n",
    "            metrics['best_target'] = target\n",
    "            metrics['best_sub'] = submission\n",
    "    else:\n",
    "        metrics['best_target'] = target\n",
    "        metrics['best_sub'] = submission\n",
    "    metrics['test_acc'].append(test_acc)\n",
    "    metrics['test_auc'].append(test_auc)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e42ad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207107420932957\n",
      "0.7914110429447853\n"
     ]
    }
   ],
   "source": [
    "print(np.max(metrics['test_auc']))\n",
    "print(np.max(metrics['test_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d939da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('cnn_%d.npz'%size, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
